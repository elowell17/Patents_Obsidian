 July 2024 2024 Subject Matter Eligibility Update Scope of training This training will provide a high-level overview of the new AI-related Subject Matter Eligibility examples 47-49 issued July 2024. 2 2024 Subject Matter Eligibility Update Introduction 4 2024 Subject Matter Eligibility Update Federal Register Notice • Title: 2024 Guidance Update on Patent Subject Matter Eligibility, Including on Artificial Intelligence (2024 AI SME Update) • Assists USPTO personnel and stakeholders in evaluating subject matter eligibility of claims in patent applications and patents involving inventions related to artificial intelligence (AI) – Issued in accordance with Executive Order 14110 on the “Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence” (October 2023) – Provides updates about the state of subject matter eligibility case law – Announces new examples covering AI inventions – Provides additional explanation on Step 2A of the USPTO’s subject matter eligibility analysis – The content of the FRN will be incorporated into the MPEP in due course 5 2024 Subject Matter Eligibility Update Reliance on Examples • New examples 47-49 present hypothetical claims that are analyzed under the USPTO’s subject matter eligibility guidance. – These examples should be interpreted based on the fact patterns set forth therein as other fact patterns may have different eligibility outcomes. – It is not necessary for a claim under examination to mirror an example claim to be subject matter eligible under the USPTO’s subject matter eligibility guidance. – These examples are not intended to alter the USPTO’s subject matter eligibility guidance. • These slides present the examples in abbreviated form. A more complete background and eligibility analysis may be found at www.uspto.gov/PatentEligibility • Note that the examples are illustrative only of the patent-eligibility analysis. During examination you should continue to practice compact prosecution and analyze every claim for compliance with all requirements for patentability. • Although all the claims indicated as eligible in prior examples 1-36 are still eligible today, those prior examples present analyses that may not be entirely consistent with the USPTO’s current subject matter eligibility guidance and so should be used with caution. • Examples 37-46 are still consistent with the USPTO’s current subject matter eligibility guidance. 6 2024 Subject Matter Eligibility Update Reminders Before Reviewing the Examples The flowchart in MPEP 2106, subsection III, is used to determine whether a claim satisfies the criteria for subject matter eligibility. Following the flowchart will also help you to organize your thoughts when analyzing a claim for subject matter eligibility. We will be following the flowchart in our analyses. On the following three slides, we will present a brief refresher of the enumerated categories of abstract ideas, as well as the considerations for Step 2A Prong Two and Step 2B. 7 2024 Subject Matter Eligibility Update Abstract Idea Groupings – MPEP 2106.04(a)(2) Mathematical Concepts • mathematical relationships • mathematical formulas or equations • mathematical calculations Mental Processes • concepts performed in the human mind (including an observation, evaluation, judgment, opinion) Certain Methods Of Organizing Human Activity • fundamental economic principles or practices (including hedging, insurance, mitigating risk) • commercial or legal interactions (including agreements in the form of contracts; legal obligations; advertising, marketing or sales activities or behaviors; business relations) • managing personal behavior or relationships or interactions between people (including social activities, teaching, and following rules or instructions) 8 2024 Subject Matter Eligibility Update 2A Prong Two Considerations: Details Limitations that are indicative of integration into a practical application: • Improvements to the functioning of a computer, or to any other technology or technical field - see MPEP 2106.05(a) • Applying or using a judicial exception to effect a particular treatment or prophylaxis for a disease or medical condition – see MPEP 2106.04(d)(2) • Applying the judicial exception with, or by use of, a particular machine - see MPEP 2106.05(b) • Effecting a transformation or reduction of a particular article to a different state or thing - see MPEP 2106.05(c) • Applying or using the judicial exception in some other meaningful way beyond generally linking the use of the judicial exception to a particular technological environment, such that the claim as a whole is more than a drafting effort designed to monopolize the exception - see MPEP 2106.04(d)(2) and 2106.05(e) Limitations that are not indicative of integration into a practical application: • Adding the words “apply it” (or an equivalent) with the judicial exception, or mere instructions to implement an abstract idea on a computer, or merely uses a computer as a tool to perform an abstract idea - see MPEP 2106.05(f) • Adding insignificant extra-solution activity to the judicial exception - see MPEP 2106.05(g) • Generally linking the use of the judicial exception to a particular technological environment or field of use – see MPEP 2106.05(h) Note: the Step 2A Prong 2 analysis does not include the “well understood, routine, conventional” consideration in MPEP 2106.05(d). This is only considered in Step 2B. 9 2024 Subject Matter Eligibility Update Step 2B adds WURC to Considerations from Step 2A Limitations that are indicative of an inventive concept (aka “significantly more”): Limitations that are not indicative of an inventive concept (aka “significantly more”): • Simply appending well-understood, routine, conventional activities previously known to the industry, specified at a high level of generality, to the judicial exception (WURC) - see MPEP 2106.05(d) and 2106.07(a)III. • Adding a specific limitation other than what is well-understood, routine, conventional activity in the field - see MPEP 2106.05(d) Step 2B adds WURC • Adding the words “apply it” (or an equivalent) with the judicial exception, or mere instructions to implement an abstract idea on a computer, or merely uses a computer as a tool to perform an abstract idea - see MPEP 2106.05(f) • Adding insignificant extra-solution activity to the judicial exception - see MPEP 2106.05(g) • Generally linking the use of the judicial exception to a particular technological environment or field of use – see MPEP 2106.05(h) • Improvements to the functioning of a computer, or to any other technology or technical field - see MPEP 2106.05(a) • Applying the judicial exception with, or by use of, a particular machine - see MPEP 2106.05(b) • Effecting a transformation or reduction of a particular article to a different state or thing - see MPEP 2106.05(c) • Applying or using the judicial exception in some other meaningful way beyond generally linking the use of the judicial exception to a particular technological environment, such that the claim as a whole is more than a drafting effort designed to monopolize the exception - see MPEP 2106.04(d)(2) and 2106.05(e) Considerations from Step 2A 2024 Subject Matter Eligibility Update New Examples Illustrating Application of the USPTO’s Subject Matter Eligibility Guidance to AI Inventions 2024 Subject Matter Eligibility Update Examples For Discussion Examples • Example 47: Anomaly Detection • Example 48: Speech Separation • Example 49: Fibrosis Treatment Conclusion Slides Note that the examples herein are numbered consecutively beginning with number 47, because 46 examples were previously issued. 11 2024 Subject Matter Eligibility Update Example 47: Anomaly Detection 13 2024 Subject Matter Eligibility Update Anomaly Detection: Background The Problem: Anomaly detection is identifying abnormal data that deviates from expected data or from a general pattern. For example, an intrusion detection system may use anomaly detection to improve the identification of malicious network packets by recognizing that the packets are different from what is usually seen on the network. Anomaly detection is difficult for computer systems because: • The system must define a boundary between ordinary and anomalous data and accurately classify the data as such. • Small variations may be important in network security or medicine while larger deviations may be normal in less sensitive applications. • Malicious actors may attempt to make anomalies appear like ordinary activity. • Artificial Neural Networks: Artificial neural networks (ANNs) are a type of machine learning model used to perform a wide variety of complex tasks including image recognition, speech recognition, pattern recognition, and detecting anomalies. A neural network is a biologically inspired algorithm that learns from training data. The structure of an exemplary ANN has a series of layers, each comprising one or more neurons arranged in one or more neuron arrays. 14 2024 Subject Matter Eligibility Update Anomaly Detection: What Did Applicant Invent? • If the ANN detects one or more anomalies in network traffic, the ANN can determine whether the detected anomaly is associated with a malicious packet. If the detected anomaly is associated with a malicious packet, the ANN may cause a network device to drop the malicious packet and block future traffic from the sender of the malicious packet. By automatically detecting network intrusions or other malicious attacks, the present invention enhances network security by allowing for automatic, proactive remediation of network attacks. • The ANN may alert a human network administrator, but may also act independently to take remedial action. Unlike conventional network remediation solutions, the disclosed invention is able to remediate malicious network activity in real time. The disclosed system realizes an improvement in network security by avoiding the delay involved in waiting on a network administrator. 15 2024 Subject Matter Eligibility Update Anomaly Detection: Subject Matter Eligibility Summary Claim 1 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. 16 2024 Subject Matter Eligibility Update Anomaly Detection: Claim 1 and BRI 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. Based on the plain meaning of the words in the claim, the broadest reasonable interpretation of claim 1 is an application specific integrated circuit (ASIC) comprising neurons, each neuron comprising a register, a microprocessor, and at least one input. Every neuron has at least one connection to another neuron using a synaptic circuit. 17 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 1): Step 1 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. Evaluate Step 1: Does this claim fall within at least one statutory category? 18 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 1): Step 1 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. Step 1 = Yes. The claim recites an integrated circuit and, therefore, is a machine and/or manufacture. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 1): Step 2A Prong One Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 19 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. 20 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 1): Step 2A Prong One (cont.) 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. The claim does not recite any limitation that falls within the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). Therefore, there is no judicial exception recited in the claim. The claim recites a plurality of neurons, which are hardware components comprising a register and processing element, and a plurality of synaptic circuits which together form an ANN. As the Supreme Court has explained, ‘‘[a]t some level, all inventions embody, use, reflect, rest upon, or apply laws of nature, natural phenomena, or abstract ideas.’’ Examiners should accordingly be careful to distinguish claims that recite an exception (which require further eligibility analysis) and claims that merely involve an exception (which are eligible and do not require further eligibility analysis). 2024 Subject Matter Eligibility Update Anomaly Detection (Claim1): Step 2A Prong One (cont.) Step 2A = No. The claim is eligible because it is not directed to an abstract idea or any other judicial exception. 21 1. An application specific integrated circuit (ASIC) for an artificial neural network (ANN), the ASIC comprising: a plurality of neurons organized in an array, wherein each neuron comprises a register, a microprocessor and at least one input, and a plurality of synaptic circuits, each synaptic circuit including a memory for storing a synaptic weight, wherein each neuron is connected to at least one other neuron via one of the plurality of synaptic circuits. 22 2024 Subject Matter Eligibility Update Anomaly Detection: Subject Matter Eligibility Summary Claim 2 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. 23 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Establish the BRI 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. • The BRI of “continuous data” is any data that is measured and can take on any number of possible values. • The claimed “discretizing” includes any known discretization method, including binning and clustering, as well as numerical discretization such as rounding continuous data values or performing other basic mathematical calculations. • Based on the plain meaning of the terms and the background, the backpropagation and gradient descent algorithms are optimization algorithms that compute neural network parameters using a series of mathematical calculations. • Step (d) does not limit how the trained artificial network operates or the anomalies are detected. • The BRI of “analyzing” encompasses evaluating information, which in this claim is limited to anomalies detected by the trained ANN. • Limitation (f) requires a generic output step from the trained ANN. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Establish the BRI (cont.) Based on the plain meaning of the words in the claim, the broadest reasonable interpretation of claim 2 is a method that receives continuous training data at a computer, uses the computer to discretize the continuous training data to generate input data, trains an ANN using the input data and a selected backpropagation algorithm and gradient descent algorithm, detects and analyzes anomalies in a data set using the trained ANN, and then outputs anomaly data from the trained ANN. The claimed discretizing, detecting and analyzing steps encompass mental choices or evaluations, and the claimed discretizing and training using a backpropagation algorithm and gradient descent algorithm encompasses performing mathematical calculations. 24 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 1 25 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Evaluate Step 1: Does this claim fall within at least one statutory category? 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 1 26 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2A Prong One 27 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 28 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2A Prong One (cont.) 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Unlike claim 1, claim 2 recites several abstract ideas. “Discretizing” in step (b) may be performed by processes including rounding, binning or clustering continuous data, which may be practically performed in the human mind using observation, evaluation, judgment, and opinion. “Detecting” in step (d) encompasses observing a data set and performing an evaluation to identify anomalous data. “Analyzing” in step (e) encompasses making a determination about detected anomalies. Such mental observations or evaluations fall within the “mental processes” grouping of abstract ideas. In step (c), the backpropagation and gradient descent algorithms are mathematical calculations. Because the recited “training” explicitly recites performing mathematical calculations, the limitation falls within the “mathematical concepts” grouping of abstract ideas. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2A Prong Two (cont.) 29 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 30 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2A Prong Two (cont.) 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Step 2A = Yes. The claim as a whole does not integrate the judicial exception into a practical application. As recited in steps (a) and (f), “receiving” and “outputting” are mere data gathering and output recited at a high level of generality, and thus are insignificant extra-solution activity. Limitations (b) and (c) are recited as being performed by a computer. The computer is recited at a high level of generality and amounts to no more than mere instructions to apply the exception using a generic computer. Similarly, (d) and (e) recite “using” the ANN, but provide nothing more than mere instructions to implement an abstract idea on a generic computer. The ANN is used to generally apply the abstract idea without limiting how the trained ANN functions. The ANN is described at a high level such that it amounts to using a computer with a generic ANN to apply the abstract idea. These limitations only recite the outcomes of “detecting one or more anomalies” and “analyzing the one or more detected anomalies” and without any details about how the outcomes are accomplished. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2B 31 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. Evaluate Step 2B: Does the claim provide an inventive concept, i.e., does the claim recite additional element(s) or a combination of elements that amount to significantly more than the judicial exception in the claim? 32 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 2): Step 2B Step 2B = No The claim does not provide an inventive concept (significantly more than the abstract idea). The claim is ineligible. As explained above, the computer and ANN are at best the equivalent of merely adding the words “apply it” to the judicial exception. The receiving and outputting were considered insignificant extra solution activity. This conclusion should be reevaluated in Step 2B. The limitations are mere data gathering and output recited at a high level of generality and amount to receiving or transmitting data over a network, which is well-understood, routine, conventional activity. See MPEP 2106.05(d), subsection II. The limitations remain insignificant extra-solution activity even upon reconsideration. Even when considered in combination, the additional elements represent mere instructions to apply an exception and insignificant extra-solution activity, which cannot provide an inventive concept. 2. A method of using an artificial neural network (ANN) comprising: (a) receiving, at a computer, continuous training data; (b) discretizing, by the computer, the continuous training data to generate input data; (c) training, by the computer, the ANN based on the input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (d) detecting one or more anomalies in a data set using the trained ANN; (e) analyzing the one or more detected anomalies using the trained ANN to generate anomaly data; and (f) outputting the anomaly data from the trained ANN. 33 2024 Subject Matter Eligibility Update Anomaly Detection: Subject Matter Eligibility Summary Claim 3 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real-time; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Establish the BRI 34 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real time; (e) dropping the one or more malicious network packets in real time; and (f) blocking future traffic from the source address. • The BRI of the backpropagation and gradient descent algorithms is optimization algorithms that compute neural network parameters using a series of mathematical calculations. The training is performed by a computer. • Step (b) recites detecting one or more anomalies in network traffic using the trained artificial neural network (ANN). There are no details about how the trained ANN operates or how the detection is made. • Step (c) only requires associating a detected anomaly with a malicious network packet. This step does not require the use of any specific process or component. • In step (d), because the detection occurs in real time while observing network packets, the BRI is that the detection is a computer function. • Steps (e) and (f) further specify remedial actions that are executed to remediate or prevent network intrusions. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Establish the BRI (cont.) Based on the plain meaning of the words in the claim, the broadest reasonable interpretation of claim 3 is a method that trains an ANN using input data and a selected backpropagation algorithm and gradient descent algorithm, detects anomalies in network data using the trained ANN, determines that at least one detected anomaly is associated with at least one malicious network packet, detects a source address associated with the detected malicious packet in real time, drops the malicious packet in real time, and then blocks future traffic from the detected source address. 35 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real-time; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 1 36 Evaluate Step 1: Does this claim fall within at least one statutory category? 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real-time; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 1 37 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real-time; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 2A Prong One 38 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real-time; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 2A Prong One (cont.) Under the BRI, the backpropagation and gradient descent algorithms in step (a) are mathematical calculations. Because the recited “training” explicitly recites performing mathematical calculations, the limitation falls within the “mathematical concepts” grouping of abstract ideas. “Detecting” in step (b) encompasses mental observations or evaluations, e.g., a computer programmer’s mental identification of an anomaly in a data set. “Determining” in step (c) only requires associating a detected anomaly with a malicious network packet, and may be practically performed in the human mind by evaluating network packet data in light of the detected anomalies. Such mental observations or evaluations fall within the “mental processes” grouping of abstract ideas. 39 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in real time; (e) dropping the one or more malicious network packets in real time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 2A Prong Two 40 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in realtime; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 2A Prong Two (cont.) The computer is used to perform an abstract idea, as discussed with respect to claim 2, such that it amounts to no more than mere instructions to apply the exception using a generic computer. “Using” the ANN in step (b) also provides nothing more than mere instructions to implement an abstract idea on a generic computer. Determining whether the claim as a whole includes an improvement to a computer or to a technological field requires evaluation of the specification and the claim to ensure that a technical explanation of the asserted improvement is present in the specification, and that the claim reflects the asserted improvement. According to the background, existing systems detect potentially malicious network packets and can alert a network administrator to potential problems. The background explains that the invention enhances security by acting in real time to proactively prevent network intrusions. 41 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in realtime; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Anomaly Detection (Claim 3): Step 2A Prong Two (cont.) Step 2A = No. The claim is eligible because the claim as a whole integrates the judicial exception into a practical application such that the claim is not directed to the judicial exception. As claimed, steps (d)-(f) use the information from the detection to enhance security by taking proactive steps to remediate the danger after detecting the source address associated with the potentially malicious packets in real time. Steps (d)-(f) reflect the improvement described in the background. Thus, the claim as a whole integrates the judicial exception into a practical application such that the claim is not directed to the judicial exception. The additional elements in steps (d)-(f), when considered in combination, integrate the abstract idea into a practical application because the claim improves the functioning of a computer or technical field. 42 3. A method of using an artificial neural network (ANN) to detect malicious network packets comprising: (a) training, by a computer, the ANN based on input data and a selected training algorithm to generate a trained ANN, wherein the selected training algorithm includes a backpropagation algorithm and a gradient descent algorithm; (b) detecting one or more anomalies in network traffic using the trained ANN; (c) determining at least one detected anomaly is associated with one or more malicious network packets; (d) detecting a source address associated with the one or more malicious network packets in realtime; (e) dropping the one or more malicious network packets in real-time; and (f) blocking future traffic from the source address. 2024 Subject Matter Eligibility Update Example 48: Speech Separation 2024 Subject Matter Eligibility Update Speech Separation: Background The Problem: Speech separation is distinguishing one conversation or voice in the presence of interfering conversations, voices, or sounds. Typical human listeners can perceive separate sources in an acoustic mixture (for example, listening to a single conversation in a crowded, noisy restaurant). Devices have microphones to both record audio and to receive commands, but do not reliably recognize speech, or the type of speech, in noisy environments. Speech separation is difficult for computer systems because: • For a computer to “pay attention” to a single conversation or speaker, the relevant speech must be separated from the rest of the audio signal received from a microphone. • Some solutions rely on separating speech based on volume, but speakers may vary in how loudly they speak or in their distance from the microphone. • Some computer-based techniques perform well in separating different classes of audio (e.g., human speech and background noise) but perform poorly in separating audio from sources belonging to the same class (e.g., speech from different speakers). • Other solutions require training the input device to recognize a particular voice but require the user to explicitly interact with the device to provide the training data. • Further, existing speech separation systems are illsuited for distinguishing a conversation between individuals of interest as opposed to commands issued by a single user. 44 2024 Subject Matter Eligibility Update Speech Separation: What Did Applicant Invent? • The invention improves over prior speech separation methods because it provides a particular speech-separation technique that solves the problem of separating speech from different speech sources belonging to the same class, while not requiring prior knowledge of the number of speakers or speaker-specific training. • A type of Artificial Neural Network (a Deep Neural Network, or DNN) could be trained with mixed speech signals comprising a fewer number of speakers and could be used to separate speech signals from a larger number of sources. • As this speech separation process utilizes both temporal and spatial features of the speech signal and derives information based on the global properties of the input signal, it performs well with inter-speaker variability within the same audio class for applications like automatic speech recognition (ASR). 45 46 2024 Subject Matter Eligibility Update Speech Separation: Subject Matter Eligibility Summary Claim 1 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation: Claim 1 and BRI 47 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. • The claim does not put any limits on how the mixed speech signal is received in step (a). The BRI encompasses any device or mechanism for receiving the speech signal. • Step (b) specifies how the mixed speech signal is converted into a spectrogram. It also specifies obtaining a feature representation. The claim does not specify how the temporal features and the spectrogram of the mixed speech signal are obtained. • Step (c) specifies a formula to determine embedding vectors based on the result of step (b). The claim further specifies that a deep neural network is used in the determination, but the claim does not include any details about the deep neural network or how it operates. 2024 Subject Matter Eligibility Update Speech Separation: Claim 1 and BRI (cont.) Based on the plain meaning of the words in the claim, the broadest reasonable interpretation of claim 1 is a method of receiving spoken audio from different sources, deriving a temporal feature representation and a spectrogram of the audio, and using a deep neural network to calculate embedding vectors based on the temporal feature representation and a spectrogram using a mathematical formula. 48 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 1 49 Evaluate Step 1: Does this claim fall within at least one statutory category? 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 1 50 Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2A Prong One 51 Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2A Prong One (cont.) The claim recites converting the mixed speech signal into a spectrogram using a short time Fourier transform and determining embedding vectors using a formula. Step (b) recites using a mathematical calculation (a short time Fourier transform) to convert the mixed speech signal x into a spectrogram. Step (c) recites using a specific formula to calculate embedding vectors. The recited formula is clearly a mathematical formula or equation, and the determination is a mathematical calculation. Thus, the claim recites a mathematical formula or equation as well as a mathematical calculation, which fall within the mathematical concepts grouping of abstract ideas. 52 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2A Prong Two 53 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2A Prong Two (cont.) Step 2A = Yes. The claim is directed to the abstract idea. The “receiving“ limitation (a) is mere data gathering recited at a high level of generality, and is insignificant extra-solution activity. See MPEP 2106.05(g). Step (c) requires “using a deep neural network” to determine the embedding vectors. The DNN is used to apply the abstract idea (i.e., perform the mathematical calculation) without placing any limitation on how the DNN operates. The limitation amounts to mere instructions to implement an abstract idea on a computer, or merely uses a computer as a tool to perform an abstract idea. See MPEP 2106.05(f). Even when viewed in combination, these additional elements do not integrate the recited judicial exception into a practical application. 54 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2B 55 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. Evaluate Step 2B: Does the claim provide an inventive concept, i.e., does the claim recite additional element(s) or a combination of elements that amount to significantly more than the judicial exception in the claim? 56 2024 Subject Matter Eligibility Update Speech Separation (Claim 1): Step 2B 1. A speech separation method comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}; (b) converting the mixed speech signal x into a spectrogram in a time-frequency domain using a short time Fourier transform and obtaining feature representation X, wherein X corresponds to the spectrogram of the mixed speech signal x and temporal features extracted from the mixed speech signal x; and (c) using a deep neural network (DNN) to determine embedding vectors V using the formula V = fθ(X), where fθ(X) is a global function of the mixed speech signal x. Step 2B = No. The claim does not provide an inventive concept (significantly more than the abstract idea). The claim is ineligible. As explained in Step 2A Prong Two, the DNN was mere instructions to apply an exception. This conclusion does not change in Step 2B. The receiving step was considered insignificant extra solution activity, and that conclusion should be reevaluated in Step 2B. The “receiving” step is still insignificant extra-solution activity at Step 2B. It is also well-understood, routine, and conventional, as the background explains that devices have long been equipped to receive a mixed speech signal via the microphones integrated into the devices. Even when considered in combination, these additional elements represent mere instructions to apply an exception and insignificant extra-solution activity, which cannot provide an inventive concept. 57 2024 Subject Matter Eligibility Update Speech Separation: Subject Matter Eligibility Summary Claim 2 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation: Claim 2 and BRI 58 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. • Claim 2 is dependent on claim 1, and includes all the limitations required in claim 1. • The partitioning in step (d) could be performed using a k-means algorithm as indicated in the disclosure or any other algorithm known to a person of ordinary skill in the art. • The plain meaning of “applying a binary mask” in step (e) encompasses mathematical operations. • Step (f) synthesizes the speech waveforms from the masked clusters, but does not specify how. • Step (g) combines the separated speech waveforms while excluding at least one speech signal, using any known method. • Step (h) specifies that the reconstructed mixed speech signal is transmitted for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation: Claim 2 and BRI (cont.) As described above with respect to claim 1, the broadest reasonable interpretation of claim 2 is a method of receiving spoken audio from different sources, deriving a temporal feature representation and a spectrogram of the audio, and using a DNN to calculate embedding vectors based on the temporal feature representation and a spectrogram using a mathematical formula. The embedding vectors are then partitioned into clusters, the clusters are modified using binary masks, and the modified clusters are synthesized into separate speech signals. A new, combined mixed speech signal is created by excluding at least one speech signal from one source and including speech signals from other sources. The combined mixed speech signal is then transmitted. 59 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 1 60 Evaluate Step 1: Does this claim fall within at least one statutory category? 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 1 61 Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 2A Prong One 62 Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 2A Prong One (cont.) Claim 2 is a proper dependent claim, and therefore includes all the limitations of its parent claim. Therefore, the claim recites the same abstract ideas recited in steps (b) and (c) in claim 1. Steps (d) and (e) further recite partitioning the embedding vectors into clusters and applying binary masks to the clusters to create masked clusters. Nothing in the claim element precludes step (d) from being practically performed in the mind, for example, by arbitrarily selecting groups of vectors and mentally assigning them to clusters. This limitation recites a mental process. Step (e) recites the mathematical concept of generating numbers based on binary calculations. 63 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 2A Prong One (cont.) These limitations do not fall within one of the enumerated groupings of abstract ideas (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target sources; It is important to distinguish steps (b), (c), and (e), which recite mathematical concepts, from steps (f) and (g), which do not. A limitation recites a judicial exception when it sets forth or describes the judicial exception, rather than merely being based on an exception. When a limitation merely involves, or is based on, a mathematical concept without reciting it, it does not fall into the mathematical concepts grouping of abstract ideas. Further, a limitation that cannot be practically performed in the human mind does not fall into the mental processes grouping. The “certain methods of organizing human activity” grouping is limited to activity that falls within the enumerated subgroupings of fundamental economic principles or practices, commercial or legal interactions, and managing personal behavior and relationships or interactions between people, and is not to be expanded beyond these enumerated subgroupings except in rare circumstances as explained in MPEP 2106.04(a)(3). Therefore, neither step (f) nor step (g) recites an abstract idea. 64 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 2A Prong Two 65 Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 2024 Subject Matter Eligibility Update Speech Separation (Claim 2): Step 2A Prong Two (cont.) Step 2A = No. The claim is eligible because it is not directed to an abstract idea or any other judicial exception. “Transmitting” in (h) is insignificant extra-solution activity. Steps (f) and (g) allow the claim to reflect the improvement discussed in the disclosure by reciting details of how the DNN aids in the cluster assignments to correspond to the sources identified in the mixed speech signal, which are then synthesized into separate speech waveforms in the time domain and converted into a mixed speech signal, excluding audio from the undesired source. The claimed invention solves the problem of separating speech from different speech sources belonging to the same class, while not requiring prior knowledge of the number of speakers or speaker-specific training. These steps reflect the improvement described in the disclosure. Accordingly, the claim is directed to an improvement to existing computer technology or to the technology of speech separation, and the claim integrates the abstract idea into a practical application. 66 2. The speech separation method of claim 1 further comprising: (d) partitioning the embedding vectors V into clusters corresponding to the different sources sn; (e) applying binary masks to the clusters to create masked clusters; (f) synthesizing speech waveforms from the masked clusters, wherein each speech waveform corresponds to a different source sn; (g) combining the speech waveforms to generate a mixed speech signal x' by stitching together the speech waveforms corresponding to the different sources sn, excluding the speech waveform from a target source ss such that the mixed speech signal x' includes speech waveforms from the different sources sn and excludes the speech waveform from the target source ss; and (h) transmitting the mixed speech signal x' for storage to a remote location. 67 2024 Subject Matter Eligibility Update Speech Separation: Subject Matter Eligibility Summary Claim 3 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 68 2024 Subject Matter Eligibility Update Speech Separation: Claim 3 and BRI 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. • Claim 3 is a non-transitory CRM storing instructions. • Step (a) does not place any limits on how the mixed speech signal is received. • Step (b) specifies that the DNN is used to convert a time-frequency representation of the mixed speech signal into embeddings, but does not limit how the conversion is done. • The embeddings are clustered using a k-means algorithm specifically. • The plain meaning of “applying a binary mask” in step (d) encompasses mathematical operations. • Step (e) does not specify how the conversion is performed. • Step (f) uses spectral features to produce a transcript of the target source speech signal. 2024 Subject Matter Eligibility Update Speech Separation: Claim 3 and BRI (cont.) The broadest reasonable interpretation of claim 3 is a non-transitory computer-readable storage medium that stores instructions, which when executed by a processor, cause the processor to perform the steps of receiving a mixed speech signal constituting audio from different sources by a deep neural network that calculates embedding vectors from time-frequency representation of the signal. The embeddings are then partitioned into clusters and the clusters are converted into separate speech signals in the time domain. Only one specific separated speech signal of these separated speech signals is converted into words to produce a transcript. 69 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Claim + Step 1 70 Evaluate Step 1: Does this claim fall within at least one statutory category? 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Step 1 71 Step 1 = Yes. The broadest reasonable interpretation of the claim covers only statutory embodiments of a computer-readable medium in light of the disclosure and not a transitory signal. A nontransitory computer-readable storage medium falls within the “manufacture” category of invention. 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Step 2A Prong One 72 Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Step 2A Prong One (cont.) Step (b) requires converting a time-frequency representation of the mixed speech signal into embeddings in a feature space as a function of the mixed speech signal, which is a mathematical equation written in prose. Step (c) requires clustering the embeddings by a k-means clustering algorithm, which is a mathematical calculation. Step (d) obtains masked clusters by applying binary masks to the clusters, which is also a mathematical calculation. Thus, the claim recites mathematical calculations which fall within the mathematical concepts grouping of abstract ideas. 73 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Step 2A Prong Two 74 Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. 75 2024 Subject Matter Eligibility Update Speech Separation (Claim 3): Step 2A Prong Two (cont.) 3. A non-transitory computer-readable storage medium having computer-executable instructions stored thereon, which when executed by one or more processors, cause the one or more processors to perform operations comprising: (a) receiving a mixed speech signal x comprising speech from multiple different sources sn, where n ∈ {1, . . . N}, at a deep neural network (DNN) trained on source separation; (b) using the DNN to convert a time-frequency representation of the mixed speech signal x into embeddings in a feature space as a function of the mixed speech signal x; (c) clustering the embeddings using a k-means clustering algorithm; (d) applying binary masks to the clusters to obtain masked clusters; (e) converting the masked clusters into a time domain to obtain N separated speech signals corresponding to the different sources sn; and (f) extracting spectral features from a target source sd of the N separated speech signals and generating a sequence of words from the spectral features to produce a transcript of the speech signal corresponding to the target source sd. Step 2A = No. The claim is eligible because it is not directed to an abstract idea or any other judicial exception. “Receiving” the mixed speech signal is merely insignificant extra-solution data gathering. “Using the DNN” in step (b) amounts to mere instructions to implement an abstract idea on a computer, or merely using a computer as a tool to perform an abstract idea. The claimed invention solves the problem of separating speech from different speech sources belonging to the same class, while not requiring prior knowledge of the number of speakers or speaker-specific training. Steps (e) and (f) integrate the abstract idea recited in steps (b)-(d) into a practical application of speech-to-text conversion. The claim reflects the technical improvements discussed in the disclosure by reciting details of how the trained DNN aids in the cluster assignments to correspond to the sources identified in the mixed speech signal, thereby making individual transcription of each separated speech signal possible. 2024 Subject Matter Eligibility Update Example 49: Fibrosis Treatment 2024 Subject Matter Eligibility Update Fibrosis Treatment: Background The Problem: Glaucoma is a leading cause of blindness globally. The most common form is open angle glaucoma, in which irreversible vision loss results from cell and optic nerve damage caused largely by poor drainage of aqueous humor from the eye. Depending upon condition severity and the timing of diagnosis, treatment can include lifestyle adjustments, pharmaceutical eye drops, laser eye surgery, or drainage device implants to facilitate healthy drainage. • While newer drainage devices, such as microstents, are more comfortable than earlier drainage devices, postsurgery scarring and inflammation due to fibrosis remain issues. • Commonly prescribed anti-fibrotic drugs, such as drug A, can reduce scarring but do so non-specifically while causing more inflammation (“post-implantation inflammation” or “PI”) that further damages the eye. 77 78 2024 Subject Matter Eligibility Update Fibrosis Treatment: What Did Applicant Invent? • Applicant developed a new anti-fibrotic drug, Compound X, that effectively reduces scarring around a microstent implantation site in glaucoma patients at high risk of PI after microstent implant surgery, but without the undesirable side effects of known drug A. • Further, applicant describes how compound X may be topically administered in eye drop form after microstent implant surgery. • Applicant developed a polygenic risk score (PRS) model to provide a weighted PRS and identify glaucoma patients at high risk of PI. • The disclosure teaches that determining patient risk using a weighted PRS as disclosed and accordingly customizing treatment lends to better prognosis after implant surgery. • Applicant also discloses a machine learning model (“the ezAI model”). Given an input of a patient’s genotype dataset, the ezAI model calculates a weighted PRS from informative SNPs in the dataset—using multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values. 79 2024 Subject Matter Eligibility Update Fibrosis Treatment: Subject Matter Eligibility Summary Claim 1 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment: Claim 1 and BRI 80 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. • Claim 1 does not restrict how the sample is collected or genotyped in step (a). • Based on the specification, the glaucoma patient is at high risk of PI where the patient’s weighted PRS is in the top quartile of PRSs when ranked against reference PRS values established during PRS model development. The ezAI model can be a machine learning model, but the claim only recites that it uses a series of calculations to calculate a weighted PRS from alleles corresponding to informative SNPs present in a given input of a patient’s genotype dataset. In other words, the ezAI model encompasses a mathematical model. • Step (c) does not require any specific treatment or prophylaxis because the claim merely recites “administering an appropriate treatment.” 2024 Subject Matter Eligibility Update Fibrosis Treatment: Claim 1 and BRI (cont.) The BRI of claim 1 is a method of collecting and genotyping a sample to provide a genotype dataset; identifying the glaucoma patient by phenotype (at high risk of PI) based on a weighted PRS generated from informative SNPs in the genotype dataset using an ezAI model that calculates the score using multiplication to weight alleles corresponding to the informative SNPs by their effect sizes and addition to sum the weighted values; and administering a treatment to the patient at high risk of PI after microstent implant surgery. 81 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 1 82 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. Evaluate Step 1: Does this claim fall within at least one statutory category? 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 1 83 Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2A Prong One 84 Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2A Prong One Limitation (b) in the claim recites “identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score.” This step requires comparing a patient’s score against known top quartile scores, which falls into the “mental process” grouping of abstract ideas because the evaluation can be practically performed in the human mind. This limitation further recites a law of nature because it describes the naturally occurring relationship between a patient’s genotype (a particular combination of genes giving rise to PI) and phenotype (risk for PI). Limitation (b) also recites an arithmetic calculation to generate a weighted risk score, which is a “mathematical calculation” and so falls into the “mathematical concepts” grouping of abstract ideas. 85 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2A Prong Two 86 Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2A Prong Two (cont.) Step 2A = Yes. The claim is directed to the judicial exception. The limitation “(a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset” is mere data gathering. The limitation is insignificant extra-solution activity. Step (c) does not provide any information as to how the patient is to be treated, or what the treatment is, but instead covers any possible treatment that a medical professional decides to administer to the patient. As such, there are no meaningful constraints on the administering step such that the particular treatment or prophylaxis consideration would apply because it is not limited to any particular manner or type of treatment. The limitation is at most an instruction to “apply” the judicial exception. 87 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2B 88 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. Evaluate Step 2B: Does the claim provide an inventive concept, i.e., does the claim recite additional element(s) or a combination of elements that amount to significantly more than the judicial exception in the claim? 89 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 1): Step 2B (cont.) 1. A post-surgical fibrosis treatment method comprising: (a) collecting and genotyping a sample from a glaucoma patient to a provide a genotype dataset; (b) identifying the glaucoma patient as at high risk of post-implantation inflammation (PI) based on a weighted polygenic risk score that is generated from informative single-nucleotide polymorphisms (SNPs) in the genotype dataset by an ezAI model that uses multiplication to weight corresponding alleles in the dataset by their effect sizes and addition to sum the weighted values to provide the score; and (c) administering an appropriate treatment to the glaucoma patient at high risk of PI after microstent implant surgery. Step 2B = No. The claim does not provide an inventive concept (significantly more than the judicial exception). The claim is ineligible. As explained above, the “appropriate treatment” in (c) is at most an instruction to “apply” the abstract idea. Mere instructions to apply an exception cannot provide an inventive concept in Step 2B. Collecting and genotyping was considered insignificant extra solution activity in Step 2A Prong Two. This conclusion should be re-evaluated in Step 2B, which takes into account whether the extra-solution activity is well-known. “Analyzing DNA to provide sequence information or to detect allelic variants” has been recognized by the courts as a routine laboratory technique. See MPEP 2106.05(d), subsection II. This limitation therefore remains insignificant extra-solution activity even upon reconsideration, and does not amount to significantly more. Even when considered in combination, these additional elements represent mere instructions to apply an exception and insignificant extrasolution activity, which cannot provide an inventive concept. 90 2024 Subject Matter Eligibility Update Fibrosis Treatment: Subject Matter Eligibility Summary Claim 2 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Establish the BRI 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. • Claim 2 is dependent on claim 1, and includes all the limitations required in claim 1. • Claim 2 adds a “wherein” clause specifying that the appropriate treatment is Compound X eye drops. It is important to remember during claim interpretation that no limitations can be disregarded and the mere fact that a limitation appears in a wherein clause does not automatically mean that it is not given weight. Here, when the clause in limitation (c) is considered in view of the specification it is clear that the wherein clause has patentable weight. Namely, the claim requires that the appropriate treatment be Compound X eye drops, and does not make the appropriate treatment optional or simply express the result of a process step. The claim does not require any particular dosage or frequency of administration. 91 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 1 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 92 Evaluate Step 1: Does this claim fall within at least one statutory category? 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 1 93 Step 1 = Yes. The claim recites a series of steps and, therefore, is a process. 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 2A Prong One 94 Evaluate Step 2A Prong One: (a) identify the specific limitation(s) in the claim that you believe recites an abstract idea; and (b) determine whether the identified limitation(s) falls within at least one of the groupings of abstract ideas enumerated in MPEP 2106.04(a)(2). 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 2A Prong One (cont.) Because claim 2 depends from claim 1, thereby incorporating all the limitations of claim 1, it recites a judicial exception in limitation (b) for the reasons discussed earlier. As a result, it is necessary to continue onto analysis under Step 2A Prong Two. 95 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 2A Prong Two 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. 96 Evaluate Step 2A Prong Two: (a) identifying whether there are any additional elements recited in the claim beyond the judicial exception, and (b) evaluating those additional elements individually and in combination to determine whether the claim as a whole integrates the exception into a practical application 2024 Subject Matter Eligibility Update Fibrosis Treatment (Claim 2): Step 2A Prong Two (cont.) 2. The method of claim 1, wherein the appropriate treatment is Compound X eye drops. Step 2A = No. The claim is eligible because it is not directed to an abstract idea or any other judicial exception. Under the BRI, additional element (c) and the wherein clause encompass the administration of a “particular treatment” when considered in the context of the claim as a whole. Specifically, the additional elements have more than a nominal relationship to the judicial exception because they use the abstract idea of determining patient risk of PI in a manner that meaningfully limits it. That is, the abstract idea is used to identify the patient as belonging to a specific patient population (glaucoma patients at high risk of PI), and the patient is then administered a treatment (compound X eye drops instead of any common anti-fibrotic treatment, such as drug A, after microstent implant surgery) that is particular to that specific patient population (glaucoma patients at high risk of PI). Relying on the determination of patient risk to administer Compound X eye drops to glaucoma patients at high risk of PI after microstent implant surgery is therefore a particular treatment for a medical condition such that the claim as a whole integrates the judicial exception into a practical application. 97 2024 Subject Matter Eligibility Update Conclusion 99 2024 Subject Matter Eligibility Update Reminders • The 2024 AI SME Update does not reflect any new USPTO practice or procedure and is meant to be consistent with existing USPTO guidance, as set forth in the MPEP, and supplements this guidance to provide further clarity on evaluating SME for AI inventions. • USPTO's SME guidance is found in MPEP Sections 2103 through 2106.07(c) and is used to analyze claims across all technologies including AI inventions, which are generally considered to be computer-implemented inventions. • Certain areas of the SME guidance are particularly relevant to AI inventions, including (1) whether a claim recites an abstract idea (at Step 2A Prong One); and (2) whether the recited abstract idea is integrated into a practical application because the claimed invention improves the functioning of a computer or another technology or technical field (at Step 2A Prong Two). The examples provide more clarity on these concepts. • There is no fixed list of terms that render a claim eligible or ineligible. Every claim must be evaluated on a case-by-case basis using the SME guidance. • It is not necessary for a claim under examination to mirror an example claim to be subject matter eligible. 2024 Subject Matter Eligibility Update Thank you! www.uspto.gov